{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Matheus Freitas Sant'Ana\n",
    "\n",
    "Nome: Thiago Lopes David"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'uber'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\matfs\\Desktop\\Ci√™ncia dos Dados\\P2-Ciencia-dos-Dados\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_excel('uber.xlsx', sheet_name = \"Treinamento\")\n",
    "tweets_teste = pd.read_excel('uber.xlsx', sheet_name = \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber                        4.783599\n",
       "o                           3.449398\n",
       "um                          2.700944\n",
       "de                          2.570778\n",
       "e                           2.408070\n",
       "eu                          2.147738\n",
       "a√≠                          1.854865\n",
       "que                         1.496909\n",
       "a                           1.366743\n",
       "tava                        1.204035\n",
       "no                          1.204035\n",
       "do                          1.171494\n",
       "pegar                       0.976245\n",
       "com                         0.976245\n",
       "hoje                        0.943703\n",
       "fui                         0.911162\n",
       "na                          0.911162\n",
       "ne                          0.878620\n",
       "n√£o                         0.878620\n",
       "pra                         0.878620\n",
       "eh                          0.878620\n",
       "3                           0.878620\n",
       "sou                         0.878620\n",
       "sim                         0.846079\n",
       "segundos                    0.846079\n",
       "louvorzao                   0.846079\n",
       "(uns                        0.846079\n",
       "senhor                      0.846079\n",
       "@brukopinho                 0.846079\n",
       "tocando                     0.846079\n",
       "                              ...   \n",
       "ol√°,                        0.032541\n",
       "ifood                       0.032541\n",
       "pessoa                      0.032541\n",
       "kkkkkkookokkkkk@messicrf    0.032541\n",
       "sa√≠                         0.032541\n",
       "ju                          0.032541\n",
       "reabilita√ß√£o                0.032541\n",
       "first                       0.032541\n",
       "pik                         0.032541\n",
       "narrativa                   0.032541\n",
       "tweet                       0.032541\n",
       "malas                       0.032541\n",
       "\"liberal\"                   0.032541\n",
       "serraüòÇe                     0.032541\n",
       "co/aa44sw8nsevou            0.032541\n",
       "vila                        0.032541\n",
       "8                           0.032541\n",
       "brancas                     0.032541\n",
       "maisrt                      0.032541\n",
       "sil√™ncio‚Ä¶@chocohinz         0.032541\n",
       "verde                       0.032541\n",
       "enfiei                      0.032541\n",
       "espiandoboa                 0.032541\n",
       "alien                       0.032541\n",
       "risco                       0.032541\n",
       "pipoca                      0.032541\n",
       "yuji                        0.032541\n",
       "preju√≠‚Ä¶ta                   0.032541\n",
       "lara                        0.032541\n",
       "por√©m                       0.032541\n",
       "Length: 992, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame_irrelevantes = tweets.loc[tweets['Classifica√ß√£o'] == 0]\n",
    "#contagem_irrel = pd.Series(cleanup(\" \".join(DataFrame_irrelevantes[\"Treinamento\"])).split()).value_counts()\n",
    "#freqr_ir = pd.Series(contagem_irrel).value_counts(True)*100\n",
    "DataFrame_irrelevantes = tweets.loc[tweets['Classifica√ß√£o'] == 0]\n",
    "texto_ir = ''.join(DataFrame_irrelevantes['Treinamento'])\n",
    "texto_clean_ir = cleanup(texto_ir)\n",
    "lista_ir = texto_clean_ir.split()\n",
    "freq_ir = pd.Series(lista_ir).value_counts(True)*100\n",
    "freq_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber              4.834606\n",
       "de                3.265479\n",
       "e                 2.756573\n",
       "o                 2.629347\n",
       "que               2.205259\n",
       "a                 1.993215\n",
       "pra               1.908397\n",
       "eu                1.781170\n",
       "um                1.738762\n",
       "no                1.441900\n",
       "q                 1.357082\n",
       "do                1.145038\n",
       "n√£o               1.060221\n",
       "com               1.060221\n",
       "√©                 0.890585\n",
       "na                0.805768\n",
       "minha             0.763359\n",
       "ele               0.763359\n",
       "da                0.763359\n",
       "meu               0.720950\n",
       "me                0.678541\n",
       "https             0.636132\n",
       "//t               0.636132\n",
       "uma               0.636132\n",
       "mais              0.551315\n",
       "se                0.551315\n",
       "t√°                0.508906\n",
       "vai               0.508906\n",
       "em                0.466497\n",
       "por               0.466497\n",
       "                    ...   \n",
       "arrebenta         0.042409\n",
       "07                0.042409\n",
       "nervosot√¥         0.042409\n",
       "horrores          0.042409\n",
       "rindo             0.042409\n",
       "querido           0.042409\n",
       "acontecendo       0.042409\n",
       "amadurecer,       0.042409\n",
       "cpmf              0.042409\n",
       "@vitorkley        0.042409\n",
       "apanhando         0.042409\n",
       "big               0.042409\n",
       "olhem             0.042409\n",
       "ningu√©m           0.042409\n",
       "fato              0.042409\n",
       "1¬∫                0.042409\n",
       "escolateve        0.042409\n",
       "arrependimento    0.042409\n",
       "coloquei          0.042409\n",
       "roubo             0.042409\n",
       "caminhada         0.042409\n",
       "bolsort           0.042409\n",
       "üòî‚úäpeguei          0.042409\n",
       "padaria           0.042409\n",
       "claro             0.042409\n",
       "estou             0.042409\n",
       "terminando        0.042409\n",
       "guria             0.042409\n",
       "metades           0.042409\n",
       "ne                0.042409\n",
       "Length: 975, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame_relevantes = tweets.loc[tweets['Classifica√ß√£o'] == 1]\n",
    "#contagem_rel = pd.Series(cleanup(\" \".join(DataFrame_relevantes[\"Treinamento\"])).split()).value_counts()\n",
    "#contagem_rel\n",
    "DataFrame_relevantes = tweets.loc[tweets['Classifica√ß√£o'] == 1]\n",
    "texto_r = ''.join(DataFrame_relevantes['Treinamento'])\n",
    "texto_clean_r = cleanup(texto_r)\n",
    "lista_r = texto_clean_r.split()\n",
    "freq_r = pd.Series(lista_r).value_counts(True)*100\n",
    "freq_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_r = len(freq_r)\n",
    "soma_ir = len(freq_ir)\n",
    "total = soma_r + soma_ir\n",
    "\n",
    "#Dados Emp√≠ricos\n",
    "p_relevante = soma_r/total\n",
    "p_irrelevante =soma_ir/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def classificador_naive_bayes(frase):\n",
    "    \n",
    "    frase_clean = cleanup(frase)\n",
    "    lista_frase = frase_clean.split()\n",
    "    \n",
    "    #P(Frase|Relevante)\n",
    "    p_frase_relevante = freq_r.loc[lista_frase].prod()\n",
    "    \n",
    "    #P(Frase|Irrelevante)\n",
    "    p_frase_irrelevante = freq_ir.loc[lista_frase].prod()\n",
    "    \n",
    "    #P(Relevante|Frase)\n",
    "    p_relevante_frase = p_frase_relevante*p_relevante\n",
    "    \n",
    "    #P(Irrelevante|Frase)\n",
    "    p_irrelevante_frase = p_frase_irrelevante*p_irrelevante\n",
    "    \n",
    "    if p_relevante_frase > p_irrelevante_frase:\n",
    "        return 1 #relevante\n",
    "    else:\n",
    "        return 0 #irrelevante\n",
    "    \n",
    "print(classificador_naive_bayes(\"t√°\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matfs\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\matfs\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for tweet in tweets_teste[\"Teste\"]:\n",
    "    \n",
    "    tweet_clean = cleanup(tweet)\n",
    "    lista_tweet = tweet_clean.split()\n",
    "    p_relevante_frase = 0\n",
    "    p_irrelevante_frase = 0\n",
    "    \n",
    "    for k in lista_tweet:\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            #P(Frase|Relevante)\n",
    "            p_frase_relevante = freq_r.loc[k].prod()\n",
    "\n",
    "            #P(Frase|Irrelevante)\n",
    "            p_frase_irrelevante = freq_ir.loc[k].prod()\n",
    "\n",
    "            #P(Relevante|Frase)\n",
    "            p_relevante_frase = p_frase_relevante*p_relevante\n",
    "\n",
    "            #P(Irrelevante|Frase)\n",
    "            p_irrelevante_frase = p_frase_irrelevante*p_irrelevante\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            p_relevante_frase += 1/(total + soma_r)\n",
    "            p_irrelevante_frase += 1/(total + soma_ir)\n",
    "            \n",
    "            \n",
    "    if p_relevante_frase > p_irrelevante_frase:\n",
    "        tweets_teste[\"Verifica\"][i]=1\n",
    "    \n",
    "    else:\n",
    "        tweets_teste[\"Verifica\"][i]=0\n",
    "        \n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Verifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu gosto do conceito de 50% do uber eats que n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o uber errando o caminho sendo q eu to atrasad...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mano minha cabe√ßa eh meio doida tipo sair pra ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@daniela_moraess ol√°, @daniela_moraess! mandam...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o uber louquissimo, dirigindo que nem piloto d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @julialfeital: uber mulher √© outra hist√≥ria...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incr√≠vel como isso siga minha energia vital ne...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>o meu que √≥dio eu to atrasada e tive que me tr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e quando voc√™ t√° no √¥nibus e fica pensando que...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a dif√≠cil arte de pegar um uber segunda a noit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  Verifica\n",
       "0  eu gosto do conceito de 50% do uber eats que n...            0.0         1\n",
       "1  o uber errando o caminho sendo q eu to atrasad...            1.0         0\n",
       "2  mano minha cabe√ßa eh meio doida tipo sair pra ...            0.0         1\n",
       "3  @daniela_moraess ol√°, @daniela_moraess! mandam...            0.0         1\n",
       "4  o uber louquissimo, dirigindo que nem piloto d...            1.0         1\n",
       "5  rt @julialfeital: uber mulher √© outra hist√≥ria...            1.0         1\n",
       "6  incr√≠vel como isso siga minha energia vital ne...            0.0         1\n",
       "7  o meu que √≥dio eu to atrasada e tive que me tr...            0.0         1\n",
       "8  e quando voc√™ t√° no √¥nibus e fica pensando que...            1.0         0\n",
       "9  a dif√≠cil arte de pegar um uber segunda a noit...            1.0         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tweets_teste.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Verifica</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Verifica        0   1\n",
       "Classifica√ß√£o        \n",
       "0.0            37  60\n",
       "1.0            56  46"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifica√ß√£o=tweets_teste['Classifica√ß√£o']\n",
    "Treinamento=tweets_teste['Verifica']\n",
    "pd.crosstab(Classifica√ß√£o, Treinamento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
