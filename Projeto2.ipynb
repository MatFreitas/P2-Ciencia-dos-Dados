{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Matheus Freitas Sant'Ana\n",
    "\n",
    "Nome: Thiago Lopes David"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[MathDavid6]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'uber'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\matfs\\Desktop\\Ci√™ncia dos Dados\\P2-Ciencia-dos-Dados\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[!\\-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_excel('uber.xlsx', sheet_name = \"Treinamento\")\n",
    "tweets_teste = pd.read_excel('uber.xlsx', sheet_name = \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber                   4.783599\n",
       "o                      3.449398\n",
       "um                     2.700944\n",
       "de                     2.570778\n",
       "e                      2.408070\n",
       "eu                     2.147738\n",
       "a√≠                     1.854865\n",
       "que                    1.496909\n",
       "a                      1.366743\n",
       "no                     1.204035\n",
       "tava                   1.204035\n",
       "do                     1.171494\n",
       "pegar                  0.976245\n",
       "com                    0.976245\n",
       "hoje                   0.943703\n",
       "fui                    0.911162\n",
       "na                     0.911162\n",
       "pra                    0.878620\n",
       "eh                     0.878620\n",
       "3                      0.878620\n",
       "ne                     0.878620\n",
       "n√£o                    0.878620\n",
       "sou                    0.878620\n",
       "senhor                 0.846079\n",
       "(uns                   0.846079\n",
       "crist√£o                0.846079\n",
       "segundos               0.846079\n",
       "sim                    0.846079\n",
       "@brukopinho            0.846079\n",
       "tocando                0.846079\n",
       "                         ...   \n",
       "nivel                  0.032541\n",
       "atravessa              0.032541\n",
       "lutassesemaninha       0.032541\n",
       "narrativa              0.032541\n",
       "chique                 0.032541\n",
       "sil√™ncio‚Ä¶apaixonada    0.032541\n",
       "cacheado,              0.032541\n",
       "‚Äúta                    0.032541\n",
       "ja                     0.032541\n",
       "email                  0.032541\n",
       "co/9jcfv0lk4do         0.032541\n",
       "assuma                 0.032541\n",
       "passar√£o               0.032541\n",
       "99                     0.032541\n",
       "posto‚Äù                 0.032541\n",
       "guedes,                0.032541\n",
       "coisas                 0.032541\n",
       "üòÇ@bernardopkuster      0.032541\n",
       "pessoa                 0.032541\n",
       "esfriou)               0.032541\n",
       "pedimos                0.032541\n",
       "virar                  0.032541\n",
       "chamei                 0.032541\n",
       "tran√ßa,                0.032541\n",
       "buscar                 0.032541\n",
       "demasiado              0.032541\n",
       "king                   0.032541\n",
       "pesadas                0.032541\n",
       "passar*                0.032541\n",
       "venero                 0.032541\n",
       "Length: 992, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando dataframe irrelevantes e suas frequ√™ncias relativas\n",
    "DataFrame_irrelevantes = tweets.loc[tweets['Classifica√ß√£o'] == 0]\n",
    "texto_ir = ''.join(DataFrame_irrelevantes['Treinamento'])\n",
    "texto_clean_ir = cleanup(texto_ir)\n",
    "lista_ir = texto_clean_ir.split()\n",
    "freq_ir = pd.Series(lista_ir).value_counts(True)*100\n",
    "freq_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber              4.834606\n",
       "de                3.265479\n",
       "e                 2.756573\n",
       "o                 2.629347\n",
       "que               2.205259\n",
       "a                 1.993215\n",
       "pra               1.908397\n",
       "eu                1.781170\n",
       "um                1.738762\n",
       "no                1.441900\n",
       "q                 1.357082\n",
       "do                1.145038\n",
       "n√£o               1.060221\n",
       "com               1.060221\n",
       "√©                 0.890585\n",
       "na                0.805768\n",
       "da                0.763359\n",
       "minha             0.763359\n",
       "ele               0.763359\n",
       "meu               0.720950\n",
       "me                0.678541\n",
       "https             0.636132\n",
       "uma               0.636132\n",
       "//t               0.636132\n",
       "mais              0.551315\n",
       "se                0.551315\n",
       "vai               0.508906\n",
       "t√°                0.508906\n",
       "em                0.466497\n",
       "por               0.466497\n",
       "                    ...   \n",
       "partida,          0.042409\n",
       "gastado           0.042409\n",
       "pede              0.042409\n",
       "tal               0.042409\n",
       "filha             0.042409\n",
       "tbmmeu            0.042409\n",
       "@pontofrio        0.042409\n",
       "rapidinho         0.042409\n",
       "cpmf              0.042409\n",
       "falar             0.042409\n",
       "certeza,          0.042409\n",
       "ddelese           0.042409\n",
       "conversando       0.042409\n",
       "resolvo           0.042409\n",
       "sertanejo         0.042409\n",
       "daqui             0.042409\n",
       "kkkkkkrt          0.042409\n",
       "passou            0.042409\n",
       "regulam‚Ä¶status    0.042409\n",
       "ja                0.042409\n",
       "tattoo            0.042409\n",
       "hj,               0.042409\n",
       "pegava            0.042409\n",
       "palavras          0.042409\n",
       "@felipeneto       0.042409\n",
       "nego              0.042409\n",
       "eleitoral         0.042409\n",
       "assim             0.042409\n",
       "durante           0.042409\n",
       "ne                0.042409\n",
       "Length: 975, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando dataframe relevantes e suas frequ√™ncias relativas\n",
    "DataFrame_relevantes = tweets.loc[tweets['Classifica√ß√£o'] == 1]\n",
    "texto_r = ''.join(DataFrame_relevantes['Treinamento'])\n",
    "texto_clean_r = cleanup(texto_r)\n",
    "lista_r = texto_clean_r.split()\n",
    "freq_r = pd.Series(lista_r).value_counts(True)*100\n",
    "freq_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_r = len(freq_r)\n",
    "soma_ir = len(freq_ir)\n",
    "total = soma_r + soma_ir\n",
    "\n",
    "#Dados Emp√≠ricos\n",
    "p_relevante = soma_r/total\n",
    "p_irrelevante =soma_ir/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matfs\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def classificador_naive_bayes(frase):\n",
    "    \n",
    "    frase_clean = cleanup(frase)\n",
    "    lista_frase = frase_clean.split()\n",
    "    \n",
    "    #P(Frase|Relevante)\n",
    "    p_frase_relevante = freq_r.loc[lista_frase].prod()\n",
    "    \n",
    "    #P(Frase|Irrelevante)\n",
    "    p_frase_irrelevante = freq_ir.loc[lista_frase].prod()\n",
    "    \n",
    "    #P(Relevante|Frase)\n",
    "    p_relevante_frase = p_frase_relevante*p_relevante\n",
    "    \n",
    "    #P(Irrelevante|Frase)\n",
    "    p_irrelevante_frase = p_frase_irrelevante*p_irrelevante\n",
    "    \n",
    "    if p_relevante_frase > p_irrelevante_frase:\n",
    "        return 1 #relevante\n",
    "    else:\n",
    "        return 0 #irrelevante\n",
    "    \n",
    "print(classificador_naive_bayes(\"uber eh caro\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a coluna de verifica√ß√£o \n",
    "for t in range(0, len(tweets_teste['Teste'])):\n",
    "    tweets_teste['Verifica'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matfs\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\matfs\\Downloads\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for tweet in tweets_teste[\"Teste\"]:\n",
    "    \n",
    "    tweet_clean = cleanup(tweet)\n",
    "    lista_tweet = tweet_clean.split()\n",
    "    p_relevante_frase = 0\n",
    "    p_irrelevante_frase = 0\n",
    "    \n",
    "    for k in lista_tweet:\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            #P(Frase|Relevante)\n",
    "            p_frase_relevante = freq_r.loc[k].prod()\n",
    "\n",
    "            #P(Frase|Irrelevante)\n",
    "            p_frase_irrelevante = freq_ir.loc[k].prod()\n",
    "\n",
    "            #P(Relevante|Frase)\n",
    "            p_relevante_frase = p_frase_relevante*p_relevante\n",
    "\n",
    "            #P(Irrelevante|Frase)\n",
    "            p_irrelevante_frase = p_frase_irrelevante*p_irrelevante\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            p_relevante_frase += 1/(total + soma_r)\n",
    "            p_irrelevante_frase += 1/(total + soma_ir)\n",
    "            \n",
    "            \n",
    "    if p_relevante_frase > p_irrelevante_frase:\n",
    "        tweets_teste[\"Verifica\"][i]=1\n",
    "    \n",
    "    else:\n",
    "        tweets_teste[\"Verifica\"][i]=0\n",
    "        \n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tweets_teste.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosstab de quali classifica√ß√£o 'na coragem' em relevante ou irrrelevante e classifica√ß√£o de nosso naive-bayes \n",
    "Classifica√ß√£o=tweets_teste['Classifica√ß√£o']\n",
    "Treinamento=tweets_teste['Verifica']\n",
    "pd.crosstab(Classifica√ß√£o, Treinamento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivos_falsos=0\n",
    "positivos_verdadeiros=0\n",
    "negativos_falsos=0\n",
    "negativos_verdadeiros=0\n",
    "total=positivos_falsos+positivos_verdadeiros+negativos_falsos+negativos_verdadeiros\n",
    "\n",
    "i=0\n",
    "for t in tweets_teste['Verifica']:\n",
    "    if tweets_teste['Verifica'][i]==1 and tweets_teste['Classifica√ß√£o'][i]==0:\n",
    "        positivos_falsos+=1\n",
    "    if tweets_teste['Verifica'][i]==0 and tweets_teste['Classifica√ß√£o'][i]==1:\n",
    "        negativos_verdadeiros+=1\n",
    "    if tweets_teste['Verifica'][i]==1 and tweets_teste['Classifica√ß√£o'][i]==1:\n",
    "        positivos_verdadeiros+=1\n",
    "    if tweets_teste['Verifica'][i]==0 and tweets_teste['Classifica√ß√£o'][i]==0:\n",
    "        negativos_falsos+=1\n",
    "    i+=1\n",
    "    \n",
    "total=positivos_falsos+positivos_verdadeiros+negativos_falsos+negativos_verdadeiros\n",
    "porcentagem_positivos_falsos=(positivos_falsos/total)*100\n",
    "porcentagem_negativos_verdadeiros=(negativos_verdadeiros/total)*100\n",
    "porcentagem_positivos_verdadeiros=(positivos_verdadeiros/total)*100\n",
    "porcentagem_negativos_falsos=(negativos_falsos/total)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentagem de positivos verdadeiros:{}%\".format(int(porcentagem_positivos_verdadeiros)))\n",
    "print(\"Porcentagem de positivos falsos:{}%\".format(int(porcentagem_positivos_falsos)))\n",
    "print(\"Porcentagem de negativos verdadeiros:{}%\".format(int(porcentagem_negativos_verdadeiros)))\n",
    "print(\"Porcentagem de negativos falsos:{}%\".format(int(porcentagem_negativos_falsos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os resultados obtidos, obtemos uma acur√°cia de 51%, indicando que a performance do nosso classificador √© razo√°vel. Um exemplo de maneira de como poder√≠amos aprimora-lo √© dando maior \"peso\" nasa contagens a algumas palavras espec√≠ficas que j√° sabemos que nos dir√£o se a informa√ß√£o √© relevante ou n√£o, como por exemplo \"pre√ßo\" e \"cancelar\", palavras que apareceram na maioria dos tweets relevantes. Al√©m disso, para melhorar o nosso classificador, poder√≠amos ter analisado mais a fundo as mensagens com dupla nega√ß√£o ou sarcasmo que certamente impactam no resultado de nosso classificador. N√£o podemos utilizar o pr√≥prio classificador para gerar mais amostras de treinamento, pois j√° que o nosso classificador j√° est√° embutido com erros, utiliz-alo para gerar mais amostras diminuiria a acur√°cia drasticamente. Outros cen√°rios para utilizar nosso classificador sen√£o o do projeto, para calcular probabilidades em tempo real de acontecimentose e enquetes, pr√°tica utilizada pela FOX sports, por exemplo, que diz ao p√∫blico qual a chance de cada time ser campe√£o brasileiro com base nos tweets que os torcedores fazem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "Referencias utilizadas:\n",
    "\n",
    "-https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/\n",
    "\n",
    "-https://www.quora.com/What-is-Laplacian-smoothing-and-why-do-we-need-it-in-a-Naive-Bayes-classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
